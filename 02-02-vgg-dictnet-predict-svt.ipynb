{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for SVT\n",
    "\n",
    "Replicate Fig. 9 in IJCV paper Jaderberg et al. (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Ready for SVT-50, SVT test dataset with fixed lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "caffe_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "\n",
    "import os\n",
    "if os.path.isdir('./testsets/SVT-50'):\n",
    "    print 'File found.'\n",
    "else:\n",
    "    print 'SVT-50 file not found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parse XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('./testsets/SVT-50/test.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "#delete ''' to print the xml \n",
    "\n",
    "\n",
    "#for child in root:\n",
    "#    for child1 in child:\n",
    "#        print child1.tag, child1.text\n",
    "#        for child2 in child1:\n",
    "#            print child2.tag, child2.attrib\n",
    "#            for child3 in child2:\n",
    "#                print child3.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define create datalist class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Lexicon:\n",
    "    def __init__(self,xml):\n",
    "        self.imageName = xml.find('imageName').text\n",
    "        self.address = xml.find('address').text\n",
    "        self.lex = xml.find('lex').text.split(\",\")\n",
    "        self.image_width = xml.find('Resolution').attrib.get('x')\n",
    "        self.image_height = xml.find('Resolution').attrib.get('y')\n",
    "    \n",
    "    def rectangle(self,rect):\n",
    "        self.rect_width = int(rect.attrib.get('width'))\n",
    "        self.rect_height = int(rect.attrib.get('height'))\n",
    "        self.rect_x= int(rect.attrib.get('x'))\n",
    "        self.rect_y = int(rect.attrib.get('y'))\n",
    "        self.gt = rect.find('tag').text\n",
    "        \n",
    "    def rectpoint(self):\n",
    "        self.rect_lt_x = self.rect_x\n",
    "        if self.rect_lt_x < 0:\n",
    "            self.rect_lt_x = 0\n",
    "        self.rect_lt_y = self.rect_y\n",
    "        if self.rect_lt_y < 0:\n",
    "            self.rect_lt_y = 0\n",
    "        self.rect_rb_x = self.rect_x + self.rect_width\n",
    "        self.rect_rb_y = self.rect_y + self.rect_height\n",
    "\n",
    "    def withoutlex(self,label):\n",
    "        self.label = label\n",
    "    \n",
    "    def withlex(self,label):\n",
    "        self.lexlabel = label\n",
    "        self.lexnum = len(self.lex)\n",
    "        \n",
    "    def set_image_number(self,number):\n",
    "        self.image_number = number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dataList = []\n",
    "image_number = 0\n",
    "for child in root:\n",
    "    imageInfo = Lexicon(child)\n",
    "    for child1 in child.find('taggedRectangles'):\n",
    "        rectInfo = copy.copy(imageInfo)\n",
    "        rectInfo.rectangle(child1)\n",
    "        rectInfo.rectpoint()    \n",
    "        rectInfo.set_image_number(image_number)\n",
    "        dataList.append(rectInfo)\n",
    "        image_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Ready for Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, set up Python, `numpy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "caffe_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assume you have the vgg_dictnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Models found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile('models/DICTNET-VGG/dictnet_vgg_mtoc.caffemodel'):\n",
    "    print 'VGG Models found.'\n",
    "else:\n",
    "    print 'Models not found.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load net and set up input preprocessing\n",
    "\n",
    "* Set Caffe to CPU or GPU mode and load the net from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)  # if we have multiple GPUs, pick the first one\n",
    "caffe.set_mode_gpu()\n",
    "#caffe.set_mode_cpu()\n",
    "\n",
    "model_def = 'models/dictnet_vgg_deploy.prototxt'\n",
    "model_weights = 'models/DICTNET-VGG/dictnet_vgg_mtoc.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification\n",
    "\n",
    "* Now we're ready to perform classification. Even though we'll only classify one image, we'll set a batch size of 1 to demonstrate batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 100)\n"
     ]
    }
   ],
   "source": [
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "print net.blobs['data'].data.shape\n",
    "\n",
    "\n",
    "transformer.set_raw_scale('data', 255.0)\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the size of the input (we can skip this if we're happy\n",
    "#  with the default; we can also change it later, e.g., for different batch sizes)\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          1,         # 1-channel gray images\n",
    "                          32, 100)  # image size is 32x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "# print total number of prediction\n",
    "print len(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: conv1   (64, 1, 5, 5)\n",
      "layer: conv2   (128, 64, 5, 5)\n",
      "layer: conv3   (256, 128, 3, 3)\n",
      "layer: conv3_5   (512, 256, 3, 3)\n",
      "layer: conv4   (512, 512, 3, 3)\n",
      "layer: fc1   (4096, 512, 4, 13)\n",
      "layer: fc2   (4096, 4096, 1, 1)\n",
      "layer: fc_class   (88172, 4096, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def debug_model_info(net):\n",
    "    for layer_name, param in net.params.iteritems():\n",
    "        print 'layer:', layer_name, \" \", str(param[0].data.shape)\n",
    "    \n",
    "#print net.layers[1].blobs[0].na,e\n",
    "debug_model_info(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(data,number):\n",
    "    output = []\n",
    "    if number == 0:\n",
    "        length = len(data)\n",
    "    else:\n",
    "        length = number\n",
    "        \n",
    "    for itera in range(0,length):\n",
    "        \n",
    "        # set image path\n",
    "        img_path = './testsets/SVT-50/' + data[itera].imageName\n",
    "        \n",
    "        # import original image and cropped image for prediction\n",
    "        image = caffe.io.load_image(img_path, False)\n",
    "        \n",
    "        image_rectangle = image[data[itera].rect_lt_y:data[itera].rect_rb_y,data[itera].rect_lt_x:data[itera].rect_rb_x]\n",
    "        transformed_image = transformer.preprocess('data', image_rectangle)\n",
    "        \n",
    "        transformed_image -= np.mean(transformed_image)\n",
    "        \n",
    "        # copy the image data into the memory allocated for the net\n",
    "        net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "        # perform classification\n",
    "        out = copy.deepcopy(net.forward())\n",
    "        output.append(out)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...... done\n"
     ]
    }
   ],
   "source": [
    "print \"classifying......\",\n",
    "output = classify(dataList,0)\n",
    "print \"done\"\n",
    "#print output[10]['prob'][0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy with lexicon and without lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load ImageNet labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_file = './dictnet_vgg_labels.txt'\n",
    "if not os.path.exists(labels_file):\n",
    "    print 'label file does not exist'\n",
    "\n",
    "labels = np.loadtxt(labels_file, str, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without Lexicon, hit definition: label of max probability in all class same as groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def lexoff(out,data):\n",
    "    wiou_lex_hit = 0\n",
    "    wiou_lex_non_hit = 0\n",
    "    non_hit_case = []\n",
    "    \n",
    "    for output,datalist in itertools.izip(out,data):\n",
    "    \n",
    "        output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "\n",
    "        #print 'predicted class is:', output_prob.argmax()\n",
    "        #print 'predicted prob is:', output_prob.max()\n",
    "        #print 'output label:', labels[output_prob.argmax()]\n",
    "        #print 'grount truth:', datalist.gt.lower(),'\\n'\n",
    "        datalist.withoutlex(labels[output_prob.argmax()])\n",
    "        \n",
    "        if labels[output_prob.argmax()] == datalist.gt.lower():\n",
    "            wiou_lex_hit += 1\n",
    "        else:\n",
    "            wiou_lex_non_hit +=1\n",
    "            non_hit_case.append(datalist.image_number)\n",
    "            \n",
    "    print 'hit:',wiou_lex_hit,' not hit:',wiou_lex_non_hit\n",
    "    \n",
    "    wiou_accuracy = wiou_lex_hit / float(wiou_lex_hit+wiou_lex_non_hit)\n",
    "    print 'accuracy: ', wiou_accuracy\n",
    "    print 'non_hit_case: ', non_hit_case\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit: 531  not hit: 116\n",
      "accuracy:  0.820710973725\n",
      "non_hit_case:  [11, 12, 20, 25, 32, 41, 45, 59, 60, 63, 91, 92, 93, 94, 95, 96, 112, 113, 114, 117, 126, 135, 138, 147, 156, 162, 164, 167, 172, 186, 193, 201, 202, 204, 205, 206, 213, 219, 220, 231, 234, 238, 241, 248, 256, 271, 277, 283, 305, 318, 320, 327, 334, 336, 343, 344, 346, 350, 352, 358, 366, 368, 372, 377, 379, 380, 390, 398, 399, 400, 401, 402, 404, 406, 407, 409, 429, 435, 451, 455, 472, 473, 478, 486, 487, 488, 490, 491, 492, 502, 505, 507, 509, 515, 521, 537, 544, 553, 558, 559, 567, 571, 582, 588, 589, 601, 607, 608, 610, 612, 618, 623, 626, 633, 635, 637]\n"
     ]
    }
   ],
   "source": [
    "lexoff(output,dataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With Lexicon, hit definition: label of max probability in fixed lexicons same as groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def lexon(out,data):\n",
    "    with_lex_hit = 0\n",
    "    with_lex_non_hit = 0\n",
    "    gt_in_lexicons = 0\n",
    "    non_hit_case = []\n",
    "    \n",
    "    for output,datalist in itertools.izip(out,data):\n",
    "        \n",
    "        gt_in_lexicons_case = 0\n",
    "        \n",
    "        output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "        max_prob = 0\n",
    "        # read prob of every lexicon\n",
    "        for lexi in datalist.lex:\n",
    "            count = 0\n",
    "            if lexi.lower() == datalist.gt.lower():\n",
    "                gt_in_lexicons_case = 1\n",
    "\n",
    "            # check lexicon in dictnet_vgg_labels and prob\n",
    "            for index in labels:\n",
    "                if index == lexi.lower(): \n",
    "                    number = count\n",
    "                    if  output_prob[number][0][0] > max_prob:\n",
    "                        max_lexi = lexi.lower()\n",
    "                        max_prob = output_prob[number][0][0]\n",
    "                        max_arg = index\n",
    "                        max_class = number  \n",
    "                count += 1\n",
    "        \n",
    "        #print 'total lexicons number: ',len(datalist.lex)        \n",
    "        #print 'class: ', max_class \n",
    "        #print 'prob: ', max_prob\n",
    "        #print 'class label: ',  max_arg\n",
    "        #print 'grount truth: ', datalist.gt.lower(),'\\n'\n",
    "        datalist.withlex(max_arg)\n",
    "        \n",
    "        if max_arg == datalist.gt.lower():\n",
    "            with_lex_hit += 1\n",
    "        else:\n",
    "            with_lex_non_hit +=1\n",
    "            non_hit_case.append(datalist.image_number)\n",
    "        \n",
    "        gt_in_lexicons += gt_in_lexicons_case\n",
    "        \n",
    "    print 'hit:',with_lex_hit,' not hit:',with_lex_non_hit\n",
    "    print 'gt_in_lexicons: ', gt_in_lexicons\n",
    "    \n",
    "    with_accuracy = with_lex_hit / float(with_lex_hit+with_lex_non_hit)\n",
    "    print 'accuracy: ', with_accuracy\n",
    "    print 'non_hit_case: ', non_hit_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit: 627  not hit: 20\n",
      "gt_in_lexicons:  647\n",
      "accuracy:  0.969088098918\n",
      "non_hit_case:  [94, 95, 126, 205, 320, 343, 352, 366, 368, 400, 401, 407, 435, 486, 491, 582, 612, 623, 633, 635]\n"
     ]
    }
   ],
   "source": [
    "lexon(output,dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
